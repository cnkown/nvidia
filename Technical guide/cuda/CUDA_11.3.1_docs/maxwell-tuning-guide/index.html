<!DOCTYPE html
  PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-us" xml:lang="en-us">
   <head>
      <meta http-equiv="Content-Type" content="text/html; charset=utf-8"></meta>
      <meta http-equiv="X-UA-Compatible" content="IE=edge"></meta>
      <meta name="copyright" content="(C) Copyright 2005"></meta>
      <meta name="DC.rights.owner" content="(C) Copyright 2005"></meta>
      <meta name="DC.Type" content="concept"></meta>
      <meta name="DC.Title" content="Tuning CUDA Applications for Maxwell"></meta>
      <meta name="abstract" content="The programming guide to tuning CUDA Applications for GPUs based on the NVIDIA Maxwell Architecture."></meta>
      <meta name="description" content="The programming guide to tuning CUDA Applications for GPUs based on the NVIDIA Maxwell Architecture."></meta>
      <meta name="DC.Coverage" content="Programming Guides"></meta>
      <meta name="DC.subject" content="CUDA Maxwell, CUDA Maxwell tuning, CUDA Maxwell best practices, CUDA Maxwell performance"></meta>
      <meta name="keywords" content="CUDA Maxwell, CUDA Maxwell tuning, CUDA Maxwell best practices, CUDA Maxwell performance"></meta>
      <meta name="DC.Format" content="XHTML"></meta>
      <meta name="DC.Identifier" content="abstract"></meta>
      <link rel="stylesheet" type="text/css" href="../common/formatting/commonltr.css"></link>
      <link rel="stylesheet" type="text/css" href="../common/formatting/site.css"></link>
      <title>Maxwell Tuning Guide :: CUDA Toolkit Documentation</title>
      <!--[if lt IE 9]>
      <script src="../common/formatting/html5shiv-printshiv.min.js"></script>
      <![endif]-->
      <script type="text/javascript" charset="utf-8" src="//assets.adobedtm.com/b92787824f2e0e9b68dc2e993f9bd995339fe417/satelliteLib-7ba51e58dc61bcb0e9311aadd02a0108ab24cc6c.js"></script>
      <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
      <script type="text/javascript" charset="utf-8" src="../common/scripts/tynt/tynt.js"></script>
      <script type="text/javascript" charset="utf-8" src="../common/formatting/jquery.min.js"></script>
      <script type="text/javascript" charset="utf-8" src="../common/formatting/jquery.ba-hashchange.min.js"></script>
      <script type="text/javascript" charset="utf-8" src="../common/formatting/jquery.scrollintoview.min.js"></script>
      <script type="text/javascript" src="../search/htmlFileList.js"></script>
      <script type="text/javascript" src="../search/htmlFileInfoList.js"></script>
      <script type="text/javascript" src="../search/nwSearchFnt.min.js"></script>
      <script type="text/javascript" src="../search/stemmers/en_stemmer.min.js"></script>
      <script type="text/javascript" src="../search/index-1.js"></script>
      <script type="text/javascript" src="../search/index-2.js"></script>
      <script type="text/javascript" src="../search/index-3.js"></script>
      <link rel="canonical" href="http://docs.nvidia.com/cuda/maxwell-tuning-guide/index.html"></link>
      <link rel="stylesheet" type="text/css" href="../common/formatting/qwcode.highlight.css"></link>
   </head>
   <body>
      
      <header id="header"><span id="company">NVIDIA</span><span id="site-title">CUDA Toolkit Documentation</span><form id="search" method="get" action="search">
            <input type="text" name="search-text"></input><fieldset id="search-location">
               <legend>Search In:</legend>
               <label><input type="radio" name="search-type" value="site"></input>Entire Site</label>
               <label><input type="radio" name="search-type" value="document"></input>Just This Document</label></fieldset>
            <button type="reset">clear search</button>
            <button id="submit" type="submit">search</button></form>
      </header>
      <div id="site-content">
         <nav id="site-nav">
            <div class="category closed"><a href="../index.html" title="The root of the site.">CUDA Toolkit 
                  
                  
                  v11.3.1</a></div>
            <div class="category"><a href="index.html" title="Maxwell Tuning Guide">Maxwell Tuning Guide</a></div>
            <ul>
               <li>
                  <div class="section-link"><a href="#tuning-cuda-applications-for-maxwell">1.&nbsp;Maxwell Tuning Guide</a></div>
                  <ul>
                     <li>
                        <div class="section-link"><a href="#nvidia-maxwell-compute-architecture">1.1.&nbsp;NVIDIA Maxwell Compute Architecture</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cuda-best-practices">1.2.&nbsp;CUDA Best Practices</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#application-compatibility">1.3.&nbsp;Application Compatibility</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#maxwell-tuning">1.4.&nbsp;Maxwell Tuning</a></div>
                        <ul>
                           <li>
                              <div class="section-link"><a href="#smm">1.4.1.&nbsp;SMM</a></div>
                              <ul>
                                 <li>
                                    <div class="section-link"><a href="#smm-occupancy">1.4.1.1.&nbsp;Occupancy</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#smm-scheduling">1.4.1.2.&nbsp;Instruction Scheduling</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#smm-latencies">1.4.1.3.&nbsp;Instruction Latencies</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#smm-instruction-throughput">1.4.1.4.&nbsp;Instruction Throughput</a></div>
                                 </li>
                              </ul>
                           </li>
                           <li>
                              <div class="section-link"><a href="#memory-throughput">1.4.2.&nbsp;Memory Throughput</a></div>
                              <ul>
                                 <li>
                                    <div class="section-link"><a href="#l1-cache">1.4.2.1.&nbsp;Unified L1/Texture Cache</a></div>
                                 </li>
                              </ul>
                           </li>
                           <li>
                              <div class="section-link"><a href="#shared-memory">1.4.3.&nbsp;Shared Memory</a></div>
                              <ul>
                                 <li>
                                    <div class="section-link"><a href="#shared-memory-capacity">1.4.3.1.&nbsp;Shared Memory Capacity</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#shared-memory-bandwidth">1.4.3.2.&nbsp;Shared Memory Bandwidth</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#fast-shared-memory-atomics">1.4.3.3.&nbsp;Fast Shared Memory Atomics</a></div>
                                 </li>
                              </ul>
                           </li>
                           <li>
                              <div class="section-link"><a href="#dynamic-parallelism">1.4.4.&nbsp;Dynamic Parallelism</a></div>
                           </li>
                        </ul>
                     </li>
                  </ul>
               </li>
               <li>
                  <div class="section-link"><a href="#revision-history">A.&nbsp;Revision History</a></div>
               </li>
            </ul>
         </nav>
         <div id="resize-nav"></div>
         <nav id="search-results">
            <h2>Search Results</h2>
            <ol></ol>
         </nav>
         
         <div id="contents-container">
            <div id="breadcrumbs-container">
               <div id="release-info">Maxwell Tuning Guide
                  (<a href="../pdf/Maxwell_Tuning_Guide.pdf">PDF</a>)
                  -
                   
                  
                  
                  v11.3.1
                  (<a href="https://developer.nvidia.com/cuda-toolkit-archive">older</a>)
                  -
                  Last updated May 20, 2021
                  -
                  <a href="mailto:CUDAIssues@nvidia.com?subject=CUDA Toolkit Documentation Feedback: Maxwell Tuning Guide">Send Feedback</a></div>
            </div>
            <article id="contents">
               <div class="topic nested0" id="abstract"><a name="abstract" shape="rect">
                     <!-- --></a><h2 class="title topictitle1"><a href="#abstract" name="abstract" shape="rect">Tuning CUDA Applications for Maxwell</a></h2>
                  <div class="body conbody">
                     <p class="shortdesc">The programming guide to tuning CUDA Applications for GPUs based
                        on the NVIDIA Maxwell Architecture.
                     </p>
                  </div>
               </div>
               <div class="topic concept nested0" xml:lang="en-US" id="tuning-cuda-applications-for-maxwell"><a name="tuning-cuda-applications-for-maxwell" shape="rect">
                     <!-- --></a><h2 class="title topictitle1"><a href="#tuning-cuda-applications-for-maxwell" name="tuning-cuda-applications-for-maxwell" shape="rect">1.&nbsp;Maxwell Tuning Guide</a></h2>
                  <div class="topic concept nested1" xml:lang="en-US" id="nvidia-maxwell-compute-architecture"><a name="nvidia-maxwell-compute-architecture" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#nvidia-maxwell-compute-architecture" name="nvidia-maxwell-compute-architecture" shape="rect">1.1.&nbsp;NVIDIA Maxwell Compute Architecture</a></h3>
                     <div class="body conbody">
                        <p class="p">Maxwell is NVIDIA's next-generation architecture for CUDA
                           compute applications. Maxwell retains and extends the same CUDA
                           programming model as in previous NVIDIA architectures such as Fermi and
                           Kepler, and applications that follow the best practices for those
                           architectures should typically see speedups on the Maxwell architecture
                           without any code changes. This guide summarizes the ways that an
                           application can be fine-tuned to gain additional speedups by leveraging
                           Maxwell architectural features.<a name="fnsrc_1" href="#fntarg_1" shape="rect"><sup>1</sup></a></p>
                        <p class="p">Maxwell introduces an all-new design for the Streaming
                           Multiprocessor (<dfn class="term">SM</dfn>) that dramatically improves
                           energy efficiency. Although the Kepler SMX design was
                           extremely efficient for its generation, through its development,
                           NVIDIA's GPU architects saw an opportunity for another big leap forward
                           in architectural efficiency; the Maxwell SM is the realization of that
                           vision. Improvements to control logic partitioning, workload balancing,
                           clock-gating granularity, compiler-based scheduling,
                           number of instructions issued per clock cycle, and many other
                           enhancements allow the Maxwell SM (also called <dfn class="term">SMM</dfn>) to far
                           exceed Kepler SMX efficiency.
                        </p>
                        <p class="p">The first Maxwell-based GPU is codenamed <dfn class="term">GM107</dfn> and is
                           designed for use in power-limited environments like notebooks and small
                           form factor (SFF) PCs.  GM107 is described in a whitepaper entitled
                           <a class="xref" href="http://international.download.nvidia.com/geforce-com/international/pdfs/GeForce-GTX-750-Ti-Whitepaper.pdf" target="_blank" shape="rect">NVIDIA GeForce GTX 750 Ti: Featuring
                              First-Generation Maxwell GPU Technology, Designed for Extreme
                              Performance per Watt</a>.<a name="fnsrc_2" href="#fntarg_2" shape="rect"><sup>2</sup></a></p>
                        <p class="p">The first GPU using the second-generation Maxwell architecture is
                           codenamed <dfn class="term">GM204</dfn>. Second-generation Maxwell GPUs retain the
                           power efficiency of the earlier generation while delivering
                           significantly higher performance.  GM204 is described in a whitepaper
                           entitled <a class="xref" href="http://international.download.nvidia.com/geforce-com/international/pdfs/GeForce_GTX_980_Whitepaper_FINAL.PDF" target="_blank" shape="rect"><em class="ph i">NVIDIA GeForce GTX 980: Featuring
                                 Maxwell, The Most Advanced GPU Ever Made</em></a>.
                        </p>
                        <p class="p">Compute programming features of GM204 are similar to those of GM107,
                           except where explicitly noted in this guide. For details on the
                           programming features discussed in this guide, please refer to the <a class="xref" href="http://docs.nvidia.com/cuda/cuda-c-programming-guide/" target="_blank" shape="rect">CUDA C++ Programming Guide</a>.
                        </p>
                     </div>
                  </div>
                  <div class="topic concept nested1" xml:lang="en-US" id="cuda-best-practices"><a name="cuda-best-practices" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cuda-best-practices" name="cuda-best-practices" shape="rect">1.2.&nbsp;CUDA Best Practices</a></h3>
                     <div class="body conbody">
                        <p class="p">The performance guidelines and best practices described in the <a class="xref" href="http://docs.nvidia.com/cuda/cuda-c-programming-guide/" target="_blank" shape="rect">CUDA C++ Programming Guide</a> and the
                           <a class="xref" href="http://docs.nvidia.com/cuda/cuda-c-best-practices-guide/" target="_blank" shape="rect">CUDA C++ Best Practices Guide</a> apply
                           to all CUDA-capable GPU architectures. Programmers must primarily focus
                           on following those recommendations to achieve the best performance.
                        </p>
                        <div class="p">The high-priority recommendations from those guides are as follows:
                           
                           <ul class="ul">
                              <li class="li">Find ways to parallelize sequential code,</li>
                              <li class="li">Minimize data transfers between the host and the device,</li>
                              <li class="li">Adjust kernel launch configuration to maximize device
                                 utilization,
                              </li>
                              <li class="li">Ensure global memory accesses are coalesced,</li>
                              <li class="li">Minimize redundant accesses to global memory whenever
                                 possible,
                              </li>
                              <li class="li">Avoid long sequences of diverged execution by threads within
                                 the same warp.
                              </li>
                           </ul>
                        </div>
                     </div>
                  </div>
                  <div class="topic concept nested1" xml:lang="en-US" id="application-compatibility"><a name="application-compatibility" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#application-compatibility" name="application-compatibility" shape="rect">1.3.&nbsp;Application Compatibility</a></h3>
                     <div class="body conbody">
                        <p class="p">Before addressing specific performance tuning issues
                           covered in this guide, refer to the <a class="xref" href="http://docs.nvidia.com/cuda/maxwell-compatibility-guide/" target="_blank" shape="rect">Maxwell Compatibility Guide for CUDA
                              Applications</a> to ensure that your application is compiled in a
                           way that is compatible with Maxwell.
                        </p>
                     </div>
                  </div>
                  <div class="topic concept nested1" xml:lang="en-US" id="maxwell-tuning"><a name="maxwell-tuning" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#maxwell-tuning" name="maxwell-tuning" shape="rect">1.4.&nbsp;Maxwell Tuning</a></h3>
                     <div class="topic concept nested2" xml:lang="en-US" id="smm"><a name="smm" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#smm" name="smm" shape="rect">1.4.1.&nbsp;SMM</a></h3>
                        <div class="body conbody">
                           <p class="p">The Maxwell Streaming Multiprocessor, SMM, is similar in many
                              respects to the Kepler architecture's SMX.   The key enhancements
                              of SMM over SMX are geared toward improving efficiency without
                              requiring significant increases in available parallelism per SM
                              from the application.
                           </p>
                        </div>
                        <div class="topic concept nested3" xml:lang="en-US" id="smm-occupancy"><a name="smm-occupancy" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#smm-occupancy" name="smm-occupancy" shape="rect">1.4.1.1.&nbsp;Occupancy</a></h3>
                           <div class="body conbody">
                              <div class="p">The maximum number of concurrent warps per SMM remains the
                                 same as in SMX (i.e., 64), and <a class="xref" href="http://developer.download.nvidia.com/compute/cuda/CUDA_Occupancy_calculator.xls" target="_blank" shape="rect">factors influencing warp
                                    occupancy</a> remain similar or improved over SMX:
                                 
                                 
                                 <ul class="ul">
                                    <li class="li">The register file size (64k 32-bit registers) is the
                                       same as that of SMX.
                                    </li>
                                    <li class="li">The maximum registers per thread, 255, matches that of
                                       Kepler GK110.  As with Kepler, experimentation should be
                                       used to determine the optimum balance of register spilling
                                       vs. occupancy, however.
                                    </li>
                                    <li class="li">The maximum number of thread blocks per SM has been
                                       increased from 16 to 32.  This should result in an
                                       automatic occupancy improvement for kernels with small
                                       thread blocks of 64 or fewer threads (shared memory and
                                       register file resource requirements permitting).  Such
                                       kernels would have tended to under-utilize SMX, but less so
                                       SMM.
                                    </li>
                                    <li class="li">Shared memory capacity is increased (see <a class="xref" href="index.html#shared-memory-capacity" shape="rect">Shared Memory Capacity</a>).
                                    </li>
                                 </ul>
                              </div>
                              <p class="p">As such, developers can expect similar or improved occupancy
                                 on SMM without changes to their application.  At the same time,
                                 warp occupancy requirements (i.e., available parallelism) for
                                 maximum device utilization are similar to or less than those of
                                 SMX (see <a class="xref" href="index.html#smm-latencies" shape="rect">Instruction Latencies</a>).
                              </p>
                           </div>
                        </div>
                        <div class="topic concept nested3" xml:lang="en-US" id="smm-scheduling"><a name="smm-scheduling" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#smm-scheduling" name="smm-scheduling" shape="rect">1.4.1.2.&nbsp;Instruction Scheduling</a></h3>
                           <div class="body conbody">
                              <p class="p">The number of CUDA Cores per SM has been reduced to a power
                                 of two, however with Maxwell's improved execution efficiency,
                                 performance per SM is usually within 10% of Kepler performance,
                                 and the improved area efficiency of SMM means CUDA Cores per
                                 GPU will be substantially higher vs. comparable Fermi or Kepler
                                 chips.  SMM retains the same number of instruction issue slots
                                 per clock and reduces arithmetic latencies compared to the
                                 Kepler design.
                              </p>
                              <p class="p">As with SMX, each SMM has four warp schedulers.  Unlike SMX,
                                 however, all SMM core functional units are assigned to a
                                 particular scheduler, with no shared units.  Along with the
                                 selection of a power-of-two number of CUDA Cores per SM, which
                                 simplifies scheduling and reduces stall cycles, this
                                 partitioning of SM computational resources in SMM is a major
                                 component of the streamlined efficiency of SMM.
                              </p>
                              <p class="p">The power-of-two number of CUDA Cores per partition
                                 simplifies scheduling, as each of SMM's warp schedulers issue
                                 to a dedicated set of CUDA Cores equal to the warp width.  Each
                                 warp scheduler still has the flexibility to dual-issue (such as
                                 issuing a math operation to a CUDA Core in the same cycle as a
                                 memory operation to a load/store unit), but single-issue is now
                                 sufficient to fully utilize all CUDA Cores.
                              </p>
                           </div>
                        </div>
                        <div class="topic concept nested3" xml:lang="en-US" id="smm-latencies"><a name="smm-latencies" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#smm-latencies" name="smm-latencies" shape="rect">1.4.1.3.&nbsp;Instruction Latencies</a></h3>
                           <div class="body conbody">
                              <p class="p">Another major improvement of SMM is that dependent math
                                 latencies have been significantly reduced; a consequence of
                                 this is a further reduction of stall cycles, as the available
                                 warp-level parallelism (i.e., occupancy) on SMM should be equal
                                 to or greater than that of SMX (see <a class="xref" href="index.html#smm-occupancy" shape="rect">Occupancy</a>), while at the same time each math
                                 operation takes <em class="ph i">less</em> time to complete, improving
                                 utilization and throughput.
                              </p>
                           </div>
                        </div>
                        <div class="topic concept nested3" xml:lang="en-US" id="smm-instruction-throughput"><a name="smm-instruction-throughput" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#smm-instruction-throughput" name="smm-instruction-throughput" shape="rect">1.4.1.4.&nbsp;Instruction Throughput</a></h3>
                           <div class="body conbody">
                              <div class="p">The most significant changes to peak instruction throughputs
                                 in SMM are as follows:
                                 
                                 <ul class="ul">
                                    <li class="li">The change in <a class="xref" href="index.html#smm-scheduling" shape="rect">number of
                                          CUDA Cores per SM</a> brings with it a corresponding
                                       change in peak single-precision floating point operations
                                       per clock per SM.  However, since the number of SMs is
                                       typically increased, the result is an increase in aggregate
                                       peak throughput; furthermore, the scheduling and latency
                                       improvements also discussed above make this peak easier to
                                       approach.
                                    </li>
                                    <li class="li">The throughput of many integer operations including
                                       multiply, logical operations and shift is improved.  In
                                       addition, there are now specialized integer instructions
                                       that can accelerate pointer arithmetic.  These instructions
                                       are most efficient when data structures are a power of two
                                       in size.
                                    </li>
                                 </ul>
                              </div>
                              <div class="note note"><span class="notetitle">Note:</span> As was already the recommended best practice, signed
                                 arithmetic should be preferred over unsigned arithmetic
                                 wherever possible for best throughput on SMM.  The C language
                                 standard places more restrictions on overflow behavior for
                                 unsigned math, limiting compiler optimization
                                 opportunities.
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" xml:lang="en-US" id="memory-throughput"><a name="memory-throughput" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#memory-throughput" name="memory-throughput" shape="rect">1.4.2.&nbsp;Memory Throughput</a></h3>
                        <div class="topic concept nested3" xml:lang="en-US" id="l1-cache"><a name="l1-cache" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#l1-cache" name="l1-cache" shape="rect">1.4.2.1.&nbsp;Unified L1/Texture Cache</a></h3>
                           <div class="body conbody">
                              <p class="p">Maxwell combines the functionality of the L1 and texture
                                 caches into a single unit.
                              </p>
                              <p class="p">As with Kepler, global loads in Maxwell are
                                 cached in L2 only, unless using the <dfn class="term">LDG</dfn> read-only
                                 data cache mechanism introduced in Kepler.
                              </p>
                              <p class="p">In a manner similar to Kepler GK110B, GM204 retains this
                                 behavior by default but also allows applications to opt-in to
                                 caching of global loads in its unified L1/Texture cache. The
                                 opt-in mechanism is the same as with GK110B: pass the
                                 <samp class="ph codeph">-Xptxas -dlcm=ca</samp> flag to <samp class="ph codeph">nvcc</samp>
                                 at compile time.
                              </p>
                              <p class="p">Local loads also are cached in L2 only, which could increase
                                 the cost of register spilling if L1 local load hit rates were
                                 high with Kepler. The balance of occupancy versus spilling
                                 should therefore be reevaluated to ensure best performance.
                                 Especially given the improvements to arithmetic latencies, code
                                 built for Maxwell may benefit from somewhat lower occupancy
                                 (due to increased registers per thread) in exchange for lower
                                 spilling.
                              </p>
                              <p class="p">The unified L1/texture cache acts as a coalescing buffer for
                                 memory accesses, gathering up the data requested by the threads
                                 of a warp prior to delivery of that data to the warp.  This
                                 function previously was served by the separate L1 cache in
                                 Fermi and Kepler.
                              </p>
                              <p class="p">Two new device attributes were added in CUDA Toolkit
                                 6.0: <samp class="ph codeph">globalL1CacheSupported</samp> and
                                 <samp class="ph codeph">localL1CacheSupported</samp>.  Developers who wish to
                                 have separately-tuned paths for various architecture
                                 generations can use these fields to simplify the path selection
                                 process.
                              </p>
                              <div class="note note"><span class="notetitle">Note:</span> Enabling caching of globals in GM204 can affect
                                 occupancy. If per-thread-block SM resource usage would result
                                 in zero occupancy with caching enabled, the CUDA driver will
                                 override the caching selection to allow the kernel launch to
                                 succeed. This situation is reported by the profiler.
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" xml:lang="en-US" id="shared-memory"><a name="shared-memory" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#shared-memory" name="shared-memory" shape="rect">1.4.3.&nbsp;Shared Memory</a></h3>
                        <div class="topic concept nested3" xml:lang="en-US" id="shared-memory-capacity"><a name="shared-memory-capacity" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#shared-memory-capacity" name="shared-memory-capacity" shape="rect">1.4.3.1.&nbsp;Shared Memory Capacity</a></h3>
                           <div class="body conbody">
                              <p class="p">With Fermi and Kepler, shared memory and the L1 cache shared
                                 the same on-chip storage.  Maxwell, by contrast, provides
                                 dedicated space to the shared memory of each SMM, since the
                                 functionality of the L1 and texture caches have been merged in
                                 SMM. This increases the shared memory space available per SMM
                                 as compared to SMX: GM107 provides 64 KB shared memory per SMM,
                                 and GM204 further increases this to 96 KB shared memory per
                                 SMM.
                              </p>
                              <div class="p">This presents several benefits to application developers:
                                 
                                 <ul class="ul">
                                    <li class="li">Algorithms with significant shared memory capacity
                                       requirements (e.g., radix sort) see an automatic 33% to
                                       100% boost in capacity per SM on top of the aggregate boost
                                       from higher SM count.
                                    </li>
                                    <li class="li">Applications no longer need to select a preference
                                       of the L1/shared split for optimal performance.
                                       For purposes of backward compatibility with Fermi and
                                       Kepler, applications may optionally continue to specify
                                       such a preference, but the preference will be ignored
                                       on Maxwell, with the full 64 KB per SMM always going to
                                       shared memory.
                                    </li>
                                 </ul>
                              </div>
                              <div class="note note"><span class="notetitle">Note:</span> While the per-SM shared memory capacity is increased
                                 in SMM, the per-thread-block limit remains 48 KB.  For
                                 maximum flexibility on possible future GPUs, NVIDIA recommends
                                 that applications use at most 32 KB of shared memory in any one
                                 thread block, which would for example allow at least two such
                                 thread blocks to fit per SMM.
                              </div>
                           </div>
                        </div>
                        <div class="topic concept nested3" xml:lang="en-US" id="shared-memory-bandwidth"><a name="shared-memory-bandwidth" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#shared-memory-bandwidth" name="shared-memory-bandwidth" shape="rect">1.4.3.2.&nbsp;Shared Memory Bandwidth</a></h3>
                           <div class="body conbody">
                              <p class="p">Kepler SMX introduced an optional 8-byte shared memory
                                 banking mode, which had the potential to increase shared memory
                                 bandwidth per SM over Fermi for shared memory accesses of 8 or
                                 16 bytes.  However, applications could only benefit from
                                 this when storing these larger elements in shared memory (i.e.,
                                 integers and fp32 values saw no benefit), and only when the
                                 developer explicitly opted into the 8-byte bank mode via the
                                 API.
                              </p>
                              <p class="p">To simplify this, Maxwell returns to the Fermi style of
                                 shared memory banking, where banks are always four bytes wide.
                                 Aggregate shared memory bandwidth across the chip remains
                                 comparable to that of corresponding Kepler chips, given
                                 increased SM count.  In this way, all applications using shared
                                 memory can now benefit from the higher bandwidth, even when
                                 storing only four-byte items into shared memory and without
                                 specifying any particular preference via the API.
                              </p>
                           </div>
                        </div>
                        <div class="topic concept nested3" xml:lang="en-US" id="fast-shared-memory-atomics"><a name="fast-shared-memory-atomics" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#fast-shared-memory-atomics" name="fast-shared-memory-atomics" shape="rect">1.4.3.3.&nbsp;Fast Shared Memory Atomics</a></h3>
                           <div class="body conbody">
                              <p class="p">Kepler introduced a dramatically higher throughput for
                                 atomic operations to <em class="ph i">global</em> memory as compared to Fermi.
                                 However, atomic operations to <em class="ph i">shared</em> memory remained
                                 essentially unchanged: both architectures implemented shared
                                 memory atomics using a lock/update/unlock pattern that could be
                                 expensive in the case of high contention for updates to
                                 particular locations in shared memory.
                              </p>
                              <p class="p">Maxwell improves upon this by implementing native shared
                                 memory atomic operations for 32-bit integers and native
                                 shared memory 32-bit and 64-bit compare-and-swap (CAS), which
                                 can be used to implement other atomic functions with reduced
                                 overhead compared to the Fermi and Kepler methods.
                              </p>
                              <div class="note note"><span class="notetitle">Note:</span> Refer to the <a class="xref" href="http://docs.nvidia.com/cuda/cuda-c-programming-guide/" target="_blank" shape="rect">CUDA C++ Programming Guide</a>
                                 for an example implementation of an fp64
                                 <samp class="ph codeph">atomicAdd()</samp> using
                                 <samp class="ph codeph">atomicCAS()</samp>.
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" xml:lang="en-US" id="dynamic-parallelism"><a name="dynamic-parallelism" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#dynamic-parallelism" name="dynamic-parallelism" shape="rect">1.4.4.&nbsp;Dynamic Parallelism</a></h3>
                        <div class="body conbody">
                           <p class="p">GK110 introduced a new architectural feature called
                              Dynamic Parallelism, which allows the GPU to create additional
                              work for itself. A programming model enhancement leveraging
                              this feature was introduced in CUDA 5.0 to enable kernels
                              running on GK110 to launch additional kernels onto the
                              same GPU.
                           </p>
                           <p class="p">SMM brings Dynamic Parallelism into the mainstream by
                              supporting it across the product line, even in lower-power
                              chips such as GM107.  This will benefit developers, as it
                              means that applications will no longer need special-case
                              algorithm implementations for high-end GPUs that differ
                              from those usable in more power-constrained environments.
                           </p>
                        </div>
                     </div>
                  </div>
               </div>
               <div class="topic reference nested0" id="revision-history"><a name="revision-history" shape="rect">
                     <!-- --></a><h2 class="title topictitle1"><a href="#revision-history" name="revision-history" shape="rect">A.&nbsp;Revision History</a></h2>
                  <div class="body refbody">
                     <div class="section">
                        <h2 class="title sectiontitle">Version 1.0</h2>
                        <ul class="ul">
                           <li class="li">Initial Public Release</li>
                        </ul>
                     </div>
                     <div class="section">
                        <h2 class="title sectiontitle">Version 1.1</h2>
                        <ul class="ul">
                           <li class="li">Updated for second-generation Maxwell (compute capability 5.2).</li>
                        </ul>
                     </div>
                     <div class="section">
                        <h2 class="title sectiontitle">Version 1.2</h2>
                        <ul class="ul">
                           <li class="li">Updated references to the CUDA C++ Programming Guide and
                              CUDA C++ Best Practices Guide.
                           </li>
                        </ul>
                     </div>
                  </div>
               </div>
               <div class="topic concept nested0" id="notices-header"><a name="notices-header" shape="rect">
                     <!-- --></a><h2 class="title topictitle1"><a href="#notices-header" name="notices-header" shape="rect">Notices</a></h2>
                  <div class="topic reference nested1" id="notice"><a name="notice" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#notice" name="notice" shape="rect"></a></h3>
                     <div class="body refbody">
                        <div class="section notices">
                           <h3 class="title sectiontitle notices">Notice</h3>
                           <p class="p" id="notice__notice-para-1"><a name="notice__notice-para-1" shape="rect">
                                 <!-- --></a>This document is provided for information
                              purposes only and shall not be regarded as a warranty of a
                              certain functionality, condition, or quality of a product.
                              NVIDIA Corporation (“NVIDIA”) makes no representations or
                              warranties, expressed or implied, as to the accuracy or
                              completeness of the information contained in this document
                              and assumes no responsibility for any errors contained
                              herein. NVIDIA shall have no liability for the consequences
                              or use of such information or for any infringement of
                              patents or other rights of third parties that may result
                              from its use. This document is not a commitment to develop,
                              release, or deliver any Material (defined below), code, or
                              functionality.
                           </p>
                           <p class="p" id="notice__notice-para-2"><a name="notice__notice-para-2" shape="rect">
                                 <!-- --></a>NVIDIA reserves the right to make corrections, modifications,
                              enhancements, improvements, and any other changes to this
                              document, at any time without notice.
                           </p>
                           <p class="p" id="notice__notice-para-3"><a name="notice__notice-para-3" shape="rect">
                                 <!-- --></a>Customer should obtain the latest relevant information before
                              placing orders and should verify that such information is
                              current and complete.
                           </p>
                           <p class="p" id="notice__notice-para-4"><a name="notice__notice-para-4" shape="rect">
                                 <!-- --></a>NVIDIA products are sold subject to the NVIDIA standard terms and
                              conditions of sale supplied at the time of order
                              acknowledgement, unless otherwise agreed in an individual
                              sales agreement signed by authorized representatives of
                              NVIDIA and customer (“Terms of Sale”). NVIDIA hereby
                              expressly objects to applying any customer general terms and
                              conditions with regards to the purchase of the NVIDIA
                              product referenced in this document. No contractual
                              obligations are formed either directly or indirectly by this
                              document.
                           </p>
                           <p class="p" id="notice__notice-para-5"><a name="notice__notice-para-5" shape="rect">
                                 <!-- --></a>NVIDIA products are not designed, authorized, or warranted to be
                              suitable for use in medical, military, aircraft, space, or
                              life support equipment, nor in applications where failure or
                              malfunction of the NVIDIA product can reasonably be expected
                              to result in personal injury, death, or property or
                              environmental damage. NVIDIA accepts no liability for
                              inclusion and/or use of NVIDIA products in such equipment or
                              applications and therefore such inclusion and/or use is at
                              customer’s own risk.
                           </p>
                           <p class="p" id="notice__notice-para-6"><a name="notice__notice-para-6" shape="rect">
                                 <!-- --></a>NVIDIA makes no representation or warranty that products based on
                              this document will be suitable for any specified use.
                              Testing of all parameters of each product is not necessarily
                              performed by NVIDIA. It is customer’s sole responsibility to
                              evaluate and determine the applicability of any information
                              contained in this document, ensure the product is suitable
                              and fit for the application planned by customer, and perform
                              the necessary testing for the application in order to avoid
                              a default of the application or the product. Weaknesses in
                              customer’s product designs may affect the quality and
                              reliability of the NVIDIA product and may result in
                              additional or different conditions and/or requirements
                              beyond those contained in this document. NVIDIA accepts no
                              liability related to any default, damage, costs, or problem
                              which may be based on or attributable to: (i) the use of the
                              NVIDIA product in any manner that is contrary to this
                              document or (ii) customer product designs.
                           </p>
                           <p class="p" id="notice__notice-para-7"><a name="notice__notice-para-7" shape="rect">
                                 <!-- --></a>No license, either expressed or implied, is granted under any NVIDIA
                              patent right, copyright, or other NVIDIA intellectual
                              property right under this document. Information published by
                              NVIDIA regarding third-party products or services does not
                              constitute a license from NVIDIA to use such products or
                              services or a warranty or endorsement thereof. Use of such
                              information may require a license from a third party under
                              the patents or other intellectual property rights of the
                              third party, or a license from NVIDIA under the patents or
                              other intellectual property rights of NVIDIA.
                           </p>
                           <p class="p" id="notice__notice-para-8"><a name="notice__notice-para-8" shape="rect">
                                 <!-- --></a>Reproduction of information in this document is permissible only if
                              approved in advance by NVIDIA in writing, reproduced without
                              alteration and in full compliance with all applicable export
                              laws and regulations, and accompanied by all associated
                              conditions, limitations, and notices.
                           </p>
                           <p class="p" id="notice__notice-para-9"><a name="notice__notice-para-9" shape="rect">
                                 <!-- --></a>THIS DOCUMENT AND ALL NVIDIA DESIGN SPECIFICATIONS, REFERENCE
                              BOARDS, FILES, DRAWINGS, DIAGNOSTICS, LISTS, AND OTHER
                              DOCUMENTS (TOGETHER AND SEPARATELY, “MATERIALS”) ARE BEING
                              PROVIDED “AS IS.” NVIDIA MAKES NO WARRANTIES, EXPRESSED,
                              IMPLIED, STATUTORY, OR OTHERWISE WITH RESPECT TO THE
                              MATERIALS, AND EXPRESSLY DISCLAIMS ALL IMPLIED WARRANTIES OF
                              NONINFRINGEMENT, MERCHANTABILITY, AND FITNESS FOR A
                              PARTICULAR PURPOSE. TO THE EXTENT NOT PROHIBITED BY LAW, IN
                              NO EVENT WILL NVIDIA BE LIABLE FOR ANY DAMAGES, INCLUDING
                              WITHOUT LIMITATION ANY DIRECT, INDIRECT, SPECIAL,
                              INCIDENTAL, PUNITIVE, OR CONSEQUENTIAL DAMAGES, HOWEVER
                              CAUSED AND REGARDLESS OF THE THEORY OF LIABILITY, ARISING
                              OUT OF ANY USE OF THIS DOCUMENT, EVEN IF NVIDIA HAS BEEN
                              ADVISED OF THE POSSIBILITY OF SUCH DAMAGES. Notwithstanding
                              any damages that customer might incur for any reason
                              whatsoever, NVIDIA’s aggregate and cumulative liability
                              towards customer for the products described herein shall be
                              limited in accordance with the Terms of Sale for the
                              product.
                           </p>
                        </div>
                     </div>
                  </div>
                  <div class="topic reference nested1" id="vesa"><a name="vesa" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#vesa" name="vesa" shape="rect"></a></h3>
                     <div class="body refbody">
                        <div class="section notices">
                           <h3 class="title sectiontitle notices">VESA DisplayPort</h3>
                           <p class="p">DisplayPort and DisplayPort Compliance Logo, DisplayPort Compliance Logo for
                              Dual-mode Sources, and DisplayPort Compliance Logo for Active Cables are
                              trademarks owned by the Video Electronics Standards Association in the United
                              States and other countries.
                           </p>
                        </div>
                     </div>
                  </div>
                  <div class="topic reference nested1" id="hdmi"><a name="hdmi" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#hdmi" name="hdmi" shape="rect"></a></h3>
                     <div class="body refbody">
                        <div class="section notices">
                           <h3 class="title sectiontitle notices">HDMI</h3>
                           <p class="p">HDMI, the HDMI logo, and High-Definition Multimedia Interface are trademarks or
                              registered trademarks of HDMI Licensing LLC.
                           </p>
                        </div>
                     </div>
                  </div>
                  <div class="topic reference nested1" id="opencl"><a name="opencl" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#opencl" name="opencl" shape="rect"></a></h3>
                     <div class="body refbody">
                        <div class="section notices">
                           <h3 class="title sectiontitle notices">OpenCL</h3>
                           <p class="p">OpenCL is a trademark of Apple Inc. used under license to the Khronos Group Inc.</p>
                        </div>
                     </div>
                  </div>
                  <div class="topic reference nested1" id="trademarks"><a name="trademarks" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#trademarks" name="trademarks" shape="rect"></a></h3>
                     <div class="body refbody">
                        <div class="section notices">
                           <h3 class="title sectiontitle notices">Trademarks</h3>
                           <p class="p">NVIDIA and the NVIDIA logo are trademarks or registered trademarks of NVIDIA Corporation
                              in the U.S. and other countries.  Other company and product names may be trademarks of
                              the respective companies with which they are associated.
                           </p>
                        </div>
                     </div>
                  </div>
                  <div class="topic reference nested1" id="copyright-past-to-present"><a name="copyright-past-to-present" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#copyright-past-to-present" name="copyright-past-to-present" shape="rect"></a></h3>
                     <div class="body refbody">
                        <div class="section">
                           <h3 class="title sectiontitle">Copyright</h3>
                           <p class="p">© <span class="ph"></span>-<span class="ph">2021</span> NVIDIA
                              Corporation. All rights reserved.
                           </p>
                           <p class="p">This product includes software developed by the Syncro Soft SRL (http://www.sync.ro/).</p>
                        </div>
                     </div>
                  </div>
               </div>
               <div class="fn"><a name="fntarg_1" href="#fnsrc_1" shape="rect"><sup>1</sup></a>  Throughout this guide,
                  <dfn class="term">Fermi</dfn> refers to devices of compute capability 2.x,
                  <dfn class="term">Kepler</dfn> refers to devices of compute capability 3.x, and
                  <dfn class="term">Maxwell</dfn> refers to devices of compute capability
                  5.x.
               </div>
               <div class="fn"><a name="fntarg_2" href="#fnsrc_2" shape="rect"><sup>2</sup></a>  The features of GM108 are similar to
                  those of GM107.
               </div>
               
               <hr id="contents-end"></hr>
               
            </article>
         </div>
      </div>
      <script language="JavaScript" type="text/javascript" charset="utf-8" src="../common/formatting/common.min.js"></script>
      <script language="JavaScript" type="text/javascript" charset="utf-8" src="../common/scripts/google-analytics/google-analytics-write.js"></script>
      <script language="JavaScript" type="text/javascript" charset="utf-8" src="../common/scripts/google-analytics/google-analytics-tracker.js"></script>
      <script type="text/javascript">var switchTo5x=true;</script><script type="text/javascript" src="http://w.sharethis.com/button/buttons.js"></script><script type="text/javascript">stLight.options({publisher: "998dc202-a267-4d8e-bce9-14debadb8d92", doNotHash: false, doNotCopy: false, hashAddressBar: false});</script><script type="text/javascript">_satellite.pageBottom();</script></body>
</html>